{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L4N2 - Helper functions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOMohsyiNSnCDw7EnDgvSFO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykro/ML-SP1-2021/blob/main/L4N2_Helper_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhKBbQN6shw0"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import PIL.Image as Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc_context({'xtick.color':'w', 'ytick.color':'w', 'text.color':'w', 'axes.labelcolor':'w'})\n",
        "\n",
        "seed=1234\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6hST7ZvzLXd"
      },
      "source": [
        "steps = 20\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "image_size = (150, 150)\n",
        "class_names = np.array(['cat','dog'])\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "919dtEUpzlsP",
        "outputId": "1eb21a40-a1db-4a41-f767-7dd3d39c6974"
      },
      "source": [
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "68608000/68606236 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez2hk-HHzz4q",
        "outputId": "7339f449-6d95-4e16-80a3-4b9cd6d409ad"
      },
      "source": [
        "#!ls ~/.keras/datasets/cats_and_dogs_filtered/train/cats\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  \n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  \n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats') \n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs') \n",
        "\n",
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training cat images: 1000\n",
            "total training dog images: 1000\n",
            "total validation cat images: 500\n",
            "total validation dog images: 500\n",
            "--\n",
            "Total training images: 2000\n",
            "Total validation images: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ykP_6cH1niX"
      },
      "source": [
        "def build_model(layers, opt=Adam()):\n",
        "  model = Sequential(layers)\n",
        "\n",
        "  model.compile(optimizer=opt,\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "def plot_images(imgs,labels=np.array([])):\n",
        "  plt.figure(figsize=(15,15))\n",
        "  plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "  for i in range(10):\n",
        "    plt.axis(\"off\")\n",
        "    plt.subplot(4,5,i+1)\n",
        "    plt.imshow(imgs[i])\n",
        "    if labels.size:\n",
        "      plt.title(class_names[int(labels[i])])\n",
        "\n",
        "def plot_model(history, prev_history=None):\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss'] \n",
        "\n",
        "  if prev_history is not None:\n",
        "    acc = prev_history.history['accuracy'] + acc\n",
        "    val_acc = prev_history.history['val_accuracy'] + val_acc\n",
        "\n",
        "    loss = prev_history.history['loss'] + loss\n",
        "    val_loss = prev_history.history['val_loss'] + val_loss\n",
        "\n",
        "    initial_epochs = len(prev_history.history['accuracy'])\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "\n",
        "  plt.subplot(2, 1, 1)\n",
        "  plt.plot(acc, label='Training Accuracy')\n",
        "  plt.plot(val_acc, label='Validation Accuracy')\n",
        "  \n",
        "  if prev_history is not None:\n",
        "    plt.plot([initial_epochs-1,initial_epochs-1],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.setp(plt.legend().get_texts(), color='black')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.title('Training and Validation Accuracy')\n",
        "\n",
        "  plt.subplot(2, 1, 2)\n",
        "  plt.plot(loss, label='Training Loss')\n",
        "  plt.plot(val_loss, label='Validation Loss')\n",
        "\n",
        "  if prev_history is not None:\n",
        "    plt.plot([initial_epochs-1,initial_epochs-1],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "      \n",
        "  plt.legend(loc='upper right')\n",
        "  plt.setp(plt.legend().get_texts(), color='black')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.show()"
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}